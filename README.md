# ğŸ“ TransLearn â€“ AI-Powered YouTube Learning Assistant

TransLearn is a FastAPI-based backend that transforms educational YouTube videos into interactive learning content. It generates:

- âœ… Multiple-choice questions (MCQs)
- âœ… Structured notes in PDF
- âœ… Audio summaries via text-to-speech

## ğŸš€ Features

- ğŸ” Extracts and trims YouTube transcripts
- ğŸ§  Smart text chunking for optimal processing
- ğŸ§¾ MCQ generation using Groq + Llama model
- ğŸ“„ Auto-formatted notes as PDF
- ğŸ”Š Audio summaries using Google Cloud Text-to-Speech
- âš¡ FastAPI-based API with full CORS support

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/translearn.git
cd translearn
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
pip install -r requirements.txt
  



âš™ï¸ Environment Setup
Create a .env file in the root directory:
GROQ_API_KEY="your_groq_api_key"

Place your Google Cloud Text-to-Speech credentials JSON (e.g.
hip-fusion-454512-p9-51166d5109ee.json) in the root folder.

ğŸ§ª Run the Backend Server
$ uvicorn main:app --reload




ğŸ“¬ API Endpoints
â¤ GET /
Returns a welcome message.

â¤ POST /mcq
Generate MCQs from a YouTube video.

Request Body:
{
  "link": "https://www.youtube.com/watch?v=YOUR_VIDEO_ID",
  "num": 5,
  "diff": "medium"
}

Response:
[
  {
    "question": "...",
    "options": ["A", "B", "C", "D"],
    "answer": "A"
  },
  ...
]

â¤ POST /notes
Generate structured notes from video and return as PDF.

Request Body:
{
  "link": "https://www.youtube.com/watch?v=YOUR_VIDEO_ID"
}
Response: Returns a notes.pdf file for download.

â¤ POST /summary-audio
Generate a summarized spoken version of the video as audio.
{
  "link": "https://www.youtube.com/watch?v=YOUR_VIDEO_ID"
}
Response: Returns an MP3 audio file.




ğŸ›  Project Structure
.
â”œâ”€â”€ main.py                 # FastAPI app with routes
â”œâ”€â”€ back_end.py             # Core logic (MCQ, notes, voice summary)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env                    # GROQ API Key
â”œâ”€â”€ .gitignore
â”œâ”€â”€ hip-fusion-*.json       # Google TTS credentials


ğŸ”§ Dependencies
Key libraries used:

FastAPI, Uvicorn â€“ API backend

LangChain, langchain-groq â€“ LLM orchestration

FPDF â€“ PDF notes generation

youtube-transcript-api â€“ Transcript extraction

google-cloud-texttospeech â€“ Audio summary

python-dotenv, requests â€“ Utility libraries

All dependencies are listed in requirements.txt.




from back_end import main

pipeline = main()

# Generate MCQs
questions = pipeline.Mcq(link="https://youtube.com/...", num=5, diff="easy")

# Generate Notes
pdf_bytes = pipeline.Notes(link="https://youtube.com/...")

# Generate Voice Summary
audio_bytes = pipeline.Voice(link="https://youtube.com/...")




ğŸ“„ License
MIT License.
You are free to use, modify, and distribute this project with attribution.


âœ¨ Author
Kanishk Khandelwal
ğŸ”— GitHub â€¢ ğŸŒ LinkedIn